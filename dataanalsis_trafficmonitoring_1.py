# -*- coding: utf-8 -*-
"""DataAnalsis_Q2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F-aXa0DvmxW5uY5t3p6zbzH-aAoLcTn3
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from google.colab import files
from sklearn.model_selection import train_test_split
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
# Upload file
uploaded_file = files.upload()
# Get the uploaded filename
filename = list(uploaded_file.keys())[0]
# Load the CSV file into pandas
df = pd.read_csv(filename)
print("File_name:",filename)
print("Dataset loaded successfully!")
print("Dataset shape:", df.shape)
print("\nPreview of data:")
display(df.head())

# 2.3.1. DATA CLEANSING
# SAVE ORIGINAL PEDESTRIAN COUNTS FIRST
df['pedestrian_original'] = df['pedestrian']
# Convert the time columns
df['time_from'] = pd.to_datetime(df['time_from'], errors='coerce')
df['time_to'] = pd.to_datetime(df['time_to'], errors='coerce')
# Fixing the naming issues
df['name'] = df['name'].replace({
    'Padestrian Path': 'Pedestrian Path',
    'Padestrian_Path': 'Pedestrian Path'
})
# Removes duplicates
df = df.drop_duplicates()
# Creates total_count column
df['total_count'] = df[['car', 'bus', 'cyclist', 'motorbike', 'pedestrian', 'rigid']].sum(axis=1)
print("After Cleansing:", df.shape)

# 2.3.2. DATA RESHAPING
df['hour'] = df['time_from'].dt.hour
df['day_of_week'] = df['time_from'].dt.dayofweek
df['date'] = df['time_from'].dt.date
df['is_weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)

# 2.3.3. RESIZING
scale_cols = ['car', 'bus', 'cyclist', 'motorbike', 'pedestrian', 'rigid', 'total_count']
scaler = MinMaxScaler()
df[scale_cols] = scaler.fit_transform(df[scale_cols])

# 2.3.4. DATA PREPARATION
df_prepared = pd.get_dummies(df, columns=['name', 'time_bucket'], drop_first=True)
print("prepared dataset", df_prepared)

# 2.3.5. FINAL OUTPUT
print("\nFINAL DATASET SUMMARY (INCLUDING ZERO COUNTS)")
print("Final Shape:", df_prepared.shape)
print("\nColumns:", df_prepared.columns.tolist())
display(df_prepared.head())
output_path = "Traffic_Data_Preprocessed_Final_WithZeros.csv"
df_prepared.to_csv(output_path, index=False)
print(f"\nPreprocessed dataset saved as: {output_path}")

# 2.4.1 Separate features and target
X = df_prepared.drop('total_count', axis=1)
y = df_prepared['total_count']
# Split the Train (70%) and Temp (30%)
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.30, random_state=42, shuffle=True
)

# 2.4.2 Split the Validation (15%) and Test (15%)
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.50, random_state=42, shuffle=True
)
# Print shapes
print("Training Set Shape:", X_train.shape, y_train.shape)
print("Validation Set Shape:", X_val.shape, y_val.shape)
print("Testing Set Shape:", X_test.shape, y_test.shape)

# Display summary statistics
print("Summary Statistics:")
display(df_prepared.describe())

# 2.5.1. HISTOGRAMS
numeric_cols = ['car', 'bus', 'cyclist', 'motorbike', 'pedestrian', 'rigid', 'total_count']
df[numeric_cols].hist(figsize=(15,10), bins=30)
plt.suptitle("Distribution of Traffic Counts", fontsize=16)
plt.show()

# 2.5.2. TRAFFIC BY HOUR OF DAY
hourly_avg = df.groupby('hour')['total_count'].mean()
plt.figure(figsize=(10,5))
plt.plot(hourly_avg.index, hourly_avg.values, marker='o')
plt.title("Average Traffic Count by Hour of the Day")
plt.xlabel("Hour")
plt.ylabel("Average Traffic Count")
plt.grid(True)
plt.show()

# 2.5.3. TRAFFIC BY DAY OF WEEK
daily_avg = df.groupby('day_of_week')['total_count'].mean()
plt.figure(figsize=(10,5))
plt.bar(daily_avg.index, daily_avg.values)
plt.title("Average Traffic Count by Day of Week (0=Mon, 6=Sun)")
plt.xlabel("Day of Week")
plt.ylabel("Average Traffic Count")
plt.show()

# 2.5.4. BAR CHART: TRAFFIC BY NAME CATEGORY
category_avg = df.groupby('name')['total_count'].mean().sort_values()
plt.figure(figsize=(10,6))
category_avg.plot(kind='bar')
plt.title("Average Total Traffic by Category (Inbound/Outbound/Pedestrian)")
plt.ylabel("Average Traffic Count")
plt.xlabel("Category")
plt.xticks(rotation=45)
plt.show()

# 2.6 Predicting Pedestrian Activity
# Target variable
y_reg = df_prepared['pedestrian']

# Features
X_reg = df_prepared.drop(['pedestrian'], axis=1)

# REMOVE datetime columns (VERY IMPORTANT)
X_reg = X_reg.drop(columns=['time_from', 'time_to', 'date'], errors='ignore')


# Train/Val/Test Split
X_trainR, X_tempR, y_trainR, y_tempR = train_test_split(
    X_reg, y_reg, test_size=0.30, random_state=42, shuffle=True)

X_valR, X_testR, y_valR, y_testR = train_test_split(
    X_tempR, y_tempR, test_size=0.50, random_state=42, shuffle=True)

# Train Random Forest
reg_model = RandomForestRegressor(n_estimators=200, random_state=42)
reg_model.fit(X_trainR, y_trainR)

# Predictions
y_val_pred = reg_model.predict(X_valR)
y_test_pred = reg_model.predict(X_testR)

# Evaluation
print("REGRESSION MODEL RESULTS")
print("VALIDATION")
print("MAE:", mean_absolute_error(y_valR, y_val_pred))
print("RMSE:", np.sqrt(mean_squared_error(y_valR, y_val_pred)))
print("R²:", r2_score(y_valR, y_val_pred))

print("\nTEST")
print("MAE:", mean_absolute_error(y_testR, y_test_pred))
print("RMSE:", np.sqrt(mean_squared_error(y_testR, y_test_pred)))
print("R²:", r2_score(y_testR, y_test_pred))

# 2.7.2 CLASSIFICATION MODEL – ANOMALY DETECTION
mean_tc = df['total_count'].mean()
std_tc = df['total_count'].std()

df['anomaly'] = df['total_count'].apply(
    lambda x: 1 if (x < mean_tc - 2*std_tc) or (x > mean_tc + 2*std_tc) else 0
)

df_prepared['anomaly'] = df['anomaly']

print("\nAnomaly Counts:")
print(df_prepared['anomaly'].value_counts())

# FIXED VERSION (no ped_class)
X_an = df_prepared.drop(['anomaly','pedestrian','pedestrian_original'], axis=1)
y_an = df_prepared['anomaly']

# Remove datetime columns
X_an = X_an.drop(columns=['time_from','time_to','date'], errors='ignore')

# Train-test split
X_trainA, X_testA, y_trainA, y_testA = train_test_split(
    X_an, y_an, test_size=0.20, random_state=42, stratify=y_an)

an_clf = RandomForestClassifier(n_estimators=200, random_state=42)
an_clf.fit(X_trainA, y_trainA)

y_predA = an_clf.predict(X_testA)

print("\n--- Anomaly Detection Classification ---")
print("Accuracy :", accuracy_score(y_testA, y_predA))
print("Precision:", precision_score(y_testA, y_predA, zero_division=0))
print("Recall   :", recall_score(y_testA, y_predA, zero_division=0))
print("F1 Score :", f1_score(y_testA, y_predA, zero_division=0))

print("\nConfusion Matrix:")
print(confusion_matrix(y_testA, y_predA))

# 2.8.1 EVALUATION: REGRESSION MODEL
print("Evaluating regression model for Pedestrian Activity")
print("MAE :", mean_absolute_error(y_testR, y_test_pred))
print("RMSE:", np.sqrt(mean_squared_error(y_testR, y_test_pred)))
print("R² Score:", r2_score(y_testR, y_test_pred))

# 2.8.2 EVALUATION: CLASSIFICATION Model
print("\n Evaluating classification model for ANOMALY DETECTION")
print("Accuracy :", accuracy_score(y_testA, y_predA))
print("Precision:", precision_score(y_testA, y_predA, zero_division=0))
print("Recall   :", recall_score(y_testA, y_predA, zero_division=0))
print("F1 Score :", f1_score(y_testA, y_predA, zero_division=0))
print("\nConfusion Matrix:")
print(confusion_matrix(y_testA, y_predA))